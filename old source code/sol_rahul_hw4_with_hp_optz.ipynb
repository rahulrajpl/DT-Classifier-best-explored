{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, recall_score, f1_score, precision_score\n",
    "from matplotlib import pyplot as  plt\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('HW_TESLA.xlt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet7525(df):\n",
    "    \"\"\"\n",
    "    This function is to generate dataset for cross validation with 25% data available\n",
    "    \"\"\"\n",
    "    df_train, df_test = train_test_split(df, test_size=0.25) # 75 % training data   \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet5050(df):\n",
    "    \"\"\"\n",
    "    This function is to generate dataset for held out validation of 25% data available\n",
    "    \"\"\"\n",
    "    df_train, X = train_test_split(df, test_size=0.5) # 50 % training data   \n",
    "    df_val, df_test = train_test_split(X, test_size=0.5) # 25 % validation data and 25 % testing data\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceSplit(df):\n",
    "    \"\"\"\n",
    "    This function is to generate balanced dataset for held out validation of 25% data available\n",
    "    \"\"\"\n",
    "    X_train = pd.concat([df[df['STATIC']==0].sample(n=1037), df[df['STATIC']==1].sample(n=1038)])\n",
    "    idx = [i for i in range(4150) if i not in X_train.index] # Getting row indices which are not in X_train    \n",
    "    df1 = df.iloc[idx]\n",
    "    X_val = pd.concat([df1[df1['STATIC']==0].sample(n=518), df1[df1['STATIC']==1].sample(n=519)])\n",
    "    idx = [i for i in range(2075) if i not in X_val.index] # Getting row indices which are not in X_val\n",
    "    X_test = df1.iloc[idx]\n",
    "    return X_train, X_val, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    df = pd.read_excel('HW_TESLA.xlt')\n",
    "    global X_train, y_train, X_test, y_test\n",
    "    df_train, df_test = splitDataSet7525(df)\n",
    "    #Separating feature matrix and corresponding labels\n",
    "    X_train = df_train.drop('STATIC',axis=1)\n",
    "    # X_val = df_val.drop('STATIC',axis=1)\n",
    "    X_test = df_test.drop('STATIC',axis=1)\n",
    "    y_train = df_train['STATIC']\n",
    "    # y_val = df_val['STATIC']\n",
    "    y_test = df_test['STATIC']\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(conf_mat, y_test, y_pred):\n",
    "\n",
    "    FP = conf_mat[0][1]\n",
    "    FN = conf_mat[1][0]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1score = f1_score(y_test, y_pred)\n",
    "\n",
    "    return FP, FN, accuracy, recall, precision, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_before_PCA():\n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    random_grid = {'criterion': ['gini','entropy'],\n",
    "                   'max_depth': [2,3,4,5,6,7],\n",
    "                   'min_samples_split':[2,3,4,5],\n",
    "                   }\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid)\n",
    "    clf_random.fit(X_train, y_train)\n",
    "    #     cv = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)\n",
    "    scores = cross_val_score(clf_random, X_train, y_train, cv=3)\n",
    "    val_score = (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    y_pred = clf_random.predict(X_test)\n",
    "    conf_mat=confusion_matrix(y_test,y_pred)\n",
    "    outcome = list(generate_report(conf_mat, y_test, y_pred))\n",
    "    outcome.insert(0, val_score[0])\n",
    "    \n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating n_components in PCA for feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64.2  92.7  99.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.\n",
      " 100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100.  100. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f22683506a0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Centering data by mean i.e. subtracting mean from each data and doing PCA\n",
    "\n",
    "# scaler=StandardScaler().fit(X_train)\n",
    "# X_train=scaler.transform(X_train)\n",
    "# X_val = scaler.transform(X_val)\n",
    "# X_test=scaler.transform(X_test)\n",
    "\n",
    "covar_matrix=PCA()\n",
    "covar_matrix.fit(X_train)\n",
    "variance = covar_matrix.explained_variance_ratio_ #calculate variance ratios\n",
    "var=np.cumsum(np.round(covar_matrix.explained_variance_ratio_, decimals=3)*100)\n",
    "print(var) #cumulative sum of variance explained with [n] features\n",
    "\n",
    "plt.ylabel('% Variance Explained')\n",
    "plt.xlabel('# of Features')\n",
    "plt.title('PCA Analysis')\n",
    "plt.ylim(50,100.5)\n",
    "plt.xlim(0,10)\n",
    "plt.style.context('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "plt.plot(var, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA():\n",
    "    global pca_X_train, pca_X_test\n",
    "    # we can reduce number of features to 5 to capture 99.8 % variance in PCA\n",
    "    pca=PCA(n_components=5)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    # Get new feature matrices from pca\n",
    "    pca_X_train=pca.transform(X_train)\n",
    "    pca_X_test=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Datasets for all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Decision Tree Algorithm after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_after_PCA():\n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    apply_PCA()\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    random_grid = {'criterion': ['gini','entropy'],\n",
    "                   'max_depth': [2,3,4,5,6,7],\n",
    "                   'min_samples_split':[2,3,4,5],\n",
    "                   }\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf_random = RandomizedSearchCV(estimator=clf, param_distributions=random_grid)\n",
    "    clf_random.fit(X_train, y_train)\n",
    "    #     cv = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)\n",
    "    scores = cross_val_score(clf_random, X_train, y_train, cv=3)\n",
    "    val_score = (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    y_pred = clf_random.predict(X_test)\n",
    "    conf_mat=confusion_matrix(y_test,y_pred)\n",
    "    outcome = list(generate_report(conf_mat, y_test, y_pred))\n",
    "    outcome.insert(0, val_score[0])\n",
    "    \n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Logistic Regression after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_after_PCA():\n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    apply_PCA()\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(pca_X_train,y_train)\n",
    "\n",
    "    # Trying ShuffleSplit\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)\n",
    "    scores = cross_val_score(clf, pca_X_train, y_train, cv=cv)\n",
    "#     print(\"cross_val_score Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    y_pred = clf.predict(pca_X_test)\n",
    "    conf_mat=confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    outcome = list(generate_report(conf_mat, y_test, y_pred))\n",
    "    outcome.insert(0, scores[0])\n",
    "    \n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Linear SVM after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_after_PCA():\n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    apply_PCA()\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(pca_X_train,y_train)\n",
    "\n",
    "    # Trying ShuffleSplit\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)\n",
    "    scores = cross_val_score(clf, pca_X_train, y_train, cv=cv)\n",
    "#     print(\"cross_val_score Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    y_pred = clf.predict(pca_X_test)\n",
    "    conf_mat=confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    outcome = list(generate_report(conf_mat, y_test, y_pred))\n",
    "    outcome.insert(0, scores[0])\n",
    "    \n",
    "    return outcome\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_after_PCA():\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = generate_data()\n",
    "    apply_PCA()\n",
    "    \n",
    "    def evaluate(model, test_features, test_labels):\n",
    "        predictions = model.predict(test_features)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = 100 - mape\n",
    "        print('Model Performance')\n",
    "        print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "        print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=10, max_depth=2, random_state=0)\n",
    "    clf.fit(pca_X_train,y_train)\n",
    "    base_accuracy = evaluate(clf, pca_X_test, y_test)\n",
    "    \n",
    "    n_estimators = [int(x) for x in np.linspace(start = 10, stop = 50, num = 5)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = list(range(1,10,1))\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split':min_samples_split,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                                  n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    clf_random.fit(pca_X_train,y_train)\n",
    "    best_random = clf_random.best_estimator_\n",
    "    random_accuracy = evaluate(best_random, pca_X_test, y_test)\n",
    "    \n",
    "    # Trying ShuffleSplit\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.33, random_state=0)\n",
    "    scores = cross_val_score(clf_random, pca_X_train, y_train, cv=cv)\n",
    "#     print(\"cross_val_score Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "    y_pred = clf_random.predict(pca_X_test)\n",
    "    conf_mat=confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    outcome = list(generate_report(conf_mat, y_test, y_pred))\n",
    "    outcome.insert(0, scores[0])\n",
    "    print(clf_random.best_params_)\n",
    "    print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the report of different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Ran the experiment with Decision Tree before PCA 1000 times\n",
      "Report: \n",
      "\n",
      "     Val_Accuracy  FP  FN  Accuracy    Recall  Precision   F1Score\n",
      "0        0.994218   0   2  0.998073  0.996890   1.000000  0.998442\n",
      "1        0.991002   1   1  0.998073  0.998392   0.998392  0.998392\n",
      "2        0.993252   5   7  0.988439  0.988710   0.991909  0.990307\n",
      "3        0.993573   1   5  0.994220  0.992051   0.998400  0.995215\n",
      "4        0.992287   5   0  0.995183  1.000000   0.992390  0.996180\n",
      "..            ...  ..  ..       ...       ...        ...       ...\n",
      "995      0.993572   7   1  0.992293  0.998400   0.988906  0.993631\n",
      "996      0.994856   5   6  0.989403  0.990164   0.991790  0.990976\n",
      "997      0.992609   4   1  0.995183  0.998382   0.993559  0.995964\n",
      "998      0.991967   4   1  0.995183  0.998410   0.993671  0.996035\n",
      "999      0.991645   5   2  0.993256  0.996885   0.992248  0.994561\n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "Averaging the above experiments: \n",
      "\n",
      "Val_Accuracy    0.993227\n",
      "FP              2.644000\n",
      "FN              3.601000\n",
      "Accuracy        0.993984\n",
      "Recall          0.994278\n",
      "Precision       0.995795\n",
      "F1Score         0.995029\n",
      "dtype: float64\n",
      "Time Taken for execution is  5158.07 Seconds\n",
      "\n",
      "\n",
      "\n",
      "Ran the experiment with Decision Tree with PCA 1000 times\n",
      "Report: \n",
      "\n",
      "     Val_Accuracy  FP  FN  Accuracy    Recall  Precision   F1Score\n",
      "0        0.993571   5   1  0.994220  0.998384   0.991974  0.995169\n",
      "1        0.991004   0   4  0.996146  0.993485   1.000000  0.996732\n",
      "2        0.993572   6   2  0.992293  0.996880   0.990698  0.993779\n",
      "3        0.991967   7   1  0.992293  0.998440   0.989181  0.993789\n",
      "4        0.995822   2   6  0.992293  0.990400   0.996779  0.993579\n",
      "..            ...  ..  ..       ...       ...        ...       ...\n",
      "995      0.992287   2   4  0.994220  0.993485   0.996732  0.995106\n",
      "996      0.992930   0   5  0.995183  0.991974   1.000000  0.995971\n",
      "997      0.993894   1   2  0.997110  0.996769   0.998382  0.997575\n",
      "998      0.991966   1   5  0.994220  0.992188   0.998428  0.995298\n",
      "999      0.991966   3   4  0.993256  0.993808   0.995349  0.994578\n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "Averaging the above experiments: \n",
      "\n",
      "Val_Accuracy    0.993243\n",
      "FP              2.640000\n",
      "FN              3.269000\n",
      "Accuracy        0.994307\n",
      "Recall          0.994798\n",
      "Precision       0.995798\n",
      "F1Score         0.995291\n",
      "dtype: float64\n",
      "Time Taken for execution is  5200.43 Seconds\n",
      "\n",
      "\n",
      "\n",
      "Ran the experiment with Logistic Regression 1000 times\n",
      "Report: \n",
      "\n",
      "     Val_Accuracy  FP  FN  Accuracy    Recall  Precision   F1Score\n",
      "0        0.991237   0   3  0.997110  0.995185   1.000000  0.997586\n",
      "1        0.990263   1   3  0.996146  0.995238   0.998408  0.996820\n",
      "2        0.993184   1   3  0.996146  0.995223   0.998403  0.996810\n",
      "3        0.992210   0   5  0.995183  0.992212   1.000000  0.996091\n",
      "4        0.995131   0   4  0.996146  0.993750   1.000000  0.996865\n",
      "..            ...  ..  ..       ...       ...        ...       ...\n",
      "995      0.993184   3   9  0.988439  0.985197   0.995017  0.990083\n",
      "996      0.985394   1   5  0.994220  0.992175   0.998425  0.995290\n",
      "997      0.987342   0   3  0.997110  0.995146   1.000000  0.997567\n",
      "998      0.993184   1   8  0.991329  0.987461   0.998415  0.992908\n",
      "999      0.995131   3   4  0.993256  0.993769   0.995320  0.994544\n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "Averaging the above experiments: \n",
      "\n",
      "Val_Accuracy    0.992720\n",
      "FP              1.090000\n",
      "FN              5.446000\n",
      "Accuracy        0.993703\n",
      "Recall          0.991346\n",
      "Precision       0.998254\n",
      "F1Score         0.994782\n",
      "dtype: float64\n",
      "Time Taken for execution is  761.51 Seconds\n",
      "\n",
      "\n",
      "\n",
      "Ran the experiment with SVM 1000 times\n",
      "Report: \n",
      "\n",
      "     Val_Accuracy  FP  FN  Accuracy    Recall  Precision   F1Score\n",
      "0        0.992210   2   8  0.990366  0.987118   0.996748  0.991909\n",
      "1        0.996105   4   2  0.994220  0.996830   0.993681  0.995253\n",
      "2        0.995131   2   4  0.994220  0.993506   0.996743  0.995122\n",
      "3        0.993184   9   0  0.991329  1.000000   0.985915  0.992908\n",
      "4        0.987342   3   6  0.991329  0.990338   0.995146  0.992736\n",
      "..            ...  ..  ..       ...       ...        ...       ...\n",
      "995      0.993184   0   2  0.998073  0.996732   1.000000  0.998363\n",
      "996      0.993184   4   3  0.993256  0.995313   0.993760  0.994536\n",
      "997      0.992210   5   5  0.990366  0.991817   0.991817  0.991817\n",
      "998      0.995131   7   0  0.993256  1.000000   0.988764  0.994350\n",
      "999      0.995131   6   1  0.993256  0.998476   0.990923  0.994685\n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "Averaging the above experiments: \n",
      "\n",
      "Val_Accuracy    0.992765\n",
      "FP              4.104000\n",
      "FN              3.180000\n",
      "Accuracy        0.992983\n",
      "Recall          0.994948\n",
      "Precision       0.993487\n",
      "F1Score         0.994205\n",
      "dtype: float64\n",
      "Time Taken for execution is  866.82 Seconds\n"
     ]
    }
   ],
   "source": [
    "algos = {'Decision Tree before PCA':DT_before_PCA,\n",
    "         'Decision Tree with PCA':DT_after_PCA,\n",
    "         'Logistic Regression':LR_after_PCA,\n",
    "         'SVM':SVM_after_PCA}\n",
    "\n",
    "for k in algos.keys():\n",
    "    count = 1000 # Experiment Count for analysis\n",
    "    algo = algos[k]\n",
    "    start = time.perf_counter()\n",
    "    val_scores = np.array([])\n",
    "    p_scores = np.array([])\n",
    "    measurements = []\n",
    "\n",
    "    for _ in range(count):\n",
    "        outcome = algo()\n",
    "        measurements.append(outcome)\n",
    "   \n",
    "  \n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         results = [executor.submit(algo) for _ in range(count)]\n",
    "\n",
    "#     for f in concurrent.futures.as_completed(results):\n",
    "#         outcome = f.result()\n",
    "#         measurements.append(outcome)\n",
    "\n",
    "    print(\"\\n\\n\\nRan the experiment with\", k , count, \"times\")\n",
    "    print(\"Report: \\n\")\n",
    "    cols = ['Val_Accuracy', 'FP', 'FN', 'Accuracy', 'Recall', 'Precision', 'F1Score']\n",
    "    df_outcome = pd.DataFrame(measurements, columns=cols)\n",
    "    print(df_outcome)\n",
    "\n",
    "    finish = time.perf_counter()\n",
    "    print(\"Averaging the above experiments: \\n\")\n",
    "    print(df_outcome.mean())\n",
    "    print(\"Time Taken for execution is \", round(finish-start, 2), 'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
